{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxxUodq7a5lG"
      },
      "source": [
        "## Chapter 2: Loading a Quantized Model"
      ],
      "id": "cxxUodq7a5lG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJox03jea5lI"
      },
      "source": [
        "### Spoilers\n",
        "\n",
        "In this chapter, we’ll:\n",
        "\n",
        "- Understand how quantization works\n",
        "- Explore the pros and cons of using different data types (FP16, BF16, FP32)\n",
        "- Introduce the concept of mixed-precision computing\n",
        "- Use BitsAndBytes to quantize a pretrained model while loading it"
      ],
      "id": "RJox03jea5lI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxI_inZXa5lI"
      },
      "source": [
        "### Setup"
      ],
      "id": "HxI_inZXa5lI"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kODUm5BmEQhI",
        "outputId": "4b10238a-4fe7-4538-c320-58143a679b72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.11/dist-packages (0.17.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: accelerate>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from trl) (1.6.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: transformers>=4.46.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.51.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.34.0->trl) (0.5.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.46.0->trl) (0.21.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.19.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "# If you're running on Colab\n",
        "!pip install datasets bitsandbytes trl"
      ],
      "id": "kODUm5BmEQhI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghoYsh-Ma5lJ"
      },
      "outputs": [],
      "source": [
        "# If you're running on runpod.io's Jupyter Template\n",
        "#!pip install datasets bitsandbytes trl transformers peft huggingface-hub accelerate safetensors pandas matplotlib"
      ],
      "id": "ghoYsh-Ma5lJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EygWIoWHa5lJ"
      },
      "source": [
        "### Imports"
      ],
      "id": "EygWIoWHa5lJ"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "F-bbRVSba5lJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from accelerate import init_empty_weights\n",
        "from accelerate.utils.modeling import find_tied_parameters, get_mixed_precision_context_manager\n",
        "from accelerate.utils.operations import convert_outputs_to_fp32\n",
        "from bitsandbytes.nn import Linear8bitLt, Linear4bit, LinearFP4, LinearNF4\n",
        "from collections import Counter\n",
        "from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer, AutoConfig\n",
        "from transformers.integrations.bitsandbytes import get_keys_to_not_convert\n",
        "from types import MethodType\n",
        "from matplotlib import pyplot as plt"
      ],
      "id": "F-bbRVSba5lJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2Sm732ba5lK"
      },
      "source": [
        "### The Goal\n",
        "\n",
        "We quantize models to reduce their memory footprint. We can easily shrink the model’s size to a quarter or an eighth of its original size. Keep in mind, however, that the more a model is quantized (i.e., the fewer bit used\n",
        "to represent its weights), the more likely its performance will be negatively affected."
      ],
      "id": "N2Sm732ba5lK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ck4CUI3a5lK"
      },
      "source": [
        "### Pre-Reqs\n",
        "\n",
        "| Type | Name | # bits | Nickname |\n",
        "|---|---|---|---|\n",
        "| FP32 | Floating Point | 32 | Full Precision |\n",
        "| BF16 | Brain Float | 16 | Half-Precision |\n",
        "| FP16 | Floating Point | 16 | Half-Precision |\n",
        "| INT8 | Integer | 8 | 8-bit Quantized |\n",
        "| FP4 | Floating Point | 4 | 4-bit Quantized |\n",
        "| NF4 | Normal Float | 4 | 4-bit Quantized |\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_sizes.png?raw=True)\n",
        "<center>Figure 2.1 - Data type’s size comparison</center>\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/model_sizes.png?raw=True)\n",
        "<center>Figure 2.2 - Representing the same model using different data types</center>"
      ],
      "id": "7ck4CUI3a5lK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lgBAQBWa5lK"
      },
      "source": [
        "### Quantization in a Nutshell"
      ],
      "id": "2lgBAQBWa5lK"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "jUXWVVeea5lK",
        "outputId": "cf3be7b7-ad4d-4d83-bed9-e00db0b61e85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-0.2066), tensor(0.2097))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "torch.manual_seed(11)\n",
        "weights = torch.randn(1000) * .07\n",
        "weights.min(), weights.max()"
      ],
      "id": "jUXWVVeea5lK"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "tdNH4z3Ka5lL",
        "outputId": "c8a6f228-80a1-48b1-925b-a82077d4db66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.2066, -0.1026,  0.0015,  0.1056,  0.2097]), tensor(0.1041))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "n_bins = 4\n",
        "bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "bin_width = bins[1]-bins[0]\n",
        "bins, bin_width"
      ],
      "id": "tdNH4z3Ka5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DZwu-1KMa5lL",
        "outputId": "065a1f59-41f3-4a1d-e826-9b117b3949d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(weights, bins=bins)\n",
        "ax.set_xlabel('Values')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "DZwu-1KMa5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "GOIQs8B2a5lL",
        "outputId": "742a9f47-931f-4651-f586-c3db25439dae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n",
            "tensor([1, 2, 1, 2, 1, 0, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 3, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "print(weights[:20])\n",
        "print(bin_indexes[:20])"
      ],
      "id": "GOIQs8B2a5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hUAjyvVga5lL",
        "outputId": "327ef040-366c-4ca3-f5a5-67bd48f10404",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
        "counts, _, _ = ax.hist(bin_indexes, bins=np.arange(n_bins+1)-.5)\n",
        "ax.set_xticks([0, 1, 2, 3])\n",
        "ax.set_xlabel('Bin Indexes')\n",
        "ax.set_title('Using Four Bins')\n",
        "fig.tight_layout()"
      ],
      "id": "hUAjyvVga5lL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZptB-NIFa5lL"
      },
      "source": [
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{n_bins}=2^{\\text{n_bits}} \\implies \\text{n_bits} = \\log_2({\\text{n_bins}})\n",
        "$$\n",
        "\n",
        "<center>Equation 2.1 - Number of bits vs number of bins</center>"
      ],
      "id": "ZptB-NIFa5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "NYE3DccGa5lL",
        "outputId": "21b3cb83-585b-4ed6-86f4-25807fed56a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "bin_values = bins[:-1]\n",
        "first_bin = bin_values[0]\n",
        "bin_values"
      ],
      "id": "NYE3DccGa5lL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSE7E8yza5lL"
      },
      "source": [
        "\n",
        "$$\n",
        "\\Large\n",
        "\\text{approx_value} = \\text{bin_index} * \\text{bin_width} + \\text{first_bin}\n",
        "$$\n",
        "\n",
        "<center>Equation 2.2 - Retrieving the (approximate) original value</center>"
      ],
      "id": "XSE7E8yza5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9ZrPq1W2a5lL",
        "outputId": "bc79f73d-ecc8-4d93-ac25-76f166bb4792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.2066, -0.1026,  0.0015,  0.1056])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "torch.arange(0, n_bins) * bin_width + first_bin"
      ],
      "id": "9ZrPq1W2a5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qb_8bViJa5lL",
        "outputId": "82c2a59e-512e-43fa-e05b-6c0251c23cf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066,  0.0015, -0.1026,\n",
            "        -0.1026, -0.1026,  0.1056, -0.1026,  0.0015,  0.0015, -0.1026, -0.1026,\n",
            "         0.0015,  0.1056, -0.2066, -0.2066])\n"
          ]
        }
      ],
      "source": [
        "approx_values = bin_indexes * bin_width + first_bin\n",
        "print(approx_values[:20])"
      ],
      "id": "qb_8bViJa5lL"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "2oCljjzVa5lM",
        "outputId": "ae7820e8-ab8c-4790-eb58-be000be312a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048,  0.0099, -0.0367,\n",
            "        -0.0174, -0.0368,  0.2025, -0.0416,  0.0918,  0.0247, -0.0921, -0.0006,\n",
            "         0.0174,  0.1101, -0.1148, -0.1115])\n"
          ]
        }
      ],
      "source": [
        "print(weights[:20])"
      ],
      "id": "2oCljjzVa5lM"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "vLqf113Xa5lM",
        "outputId": "c214603c-ecbf-44c9-c753-8704b5cee066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0615)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "mse_fn = nn.MSELoss()\n",
        "mse_fn(approx_values, weights).sqrt()"
      ],
      "id": "vLqf113Xa5lM"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "CiYSqgq9a5lM"
      },
      "outputs": [],
      "source": [
        "def quantize(weights, n_bits=8):\n",
        "    assert n_bits <= 16, \"Using more bits may very slow execution and/or crashing.\"\n",
        "    n_bins = 2**n_bits\n",
        "    bins = torch.linspace(weights.min(), weights.max(), n_bins+1)\n",
        "    first_bin = bins[0]\n",
        "    bin_width = bins[1]-bins[0]\n",
        "    bin_indexes = (weights.view(-1, 1) > bins).to(torch.int).argmin(dim=1) - 1\n",
        "    return bin_indexes, bin_width, first_bin\n",
        "\n",
        "def dequantize(bin_indexes, bin_width, first_bin):\n",
        "    approx_values = bin_indexes * bin_width + first_bin\n",
        "    return approx_values"
      ],
      "id": "CiYSqgq9a5lM"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "pp7G3d40a5lM",
        "outputId": "060c9f9c-90f6-4baf-e5e4-c8c698fbea6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-bit Quantization:\n",
            "tensor([-0.1026,  0.0015, -0.1026,  0.0015, -0.1026, -0.2066])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0615)\n",
            "\n",
            "\n",
            "4-bit Quantization:\n",
            "tensor([-0.0505,  0.0535, -0.0505,  0.0015, -0.0245, -0.1286])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0152)\n",
            "\n",
            "\n",
            "8-bit Quantization:\n",
            "tensor([-0.0359,  0.0714, -0.0261,  0.0080, -0.0131, -0.1058])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0010)\n",
            "\n",
            "\n",
            "16-bit Quantization:\n",
            "tensor([-0.0359,  0.0718, -0.0248,  0.0085, -0.0128, -0.1049])\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n",
            "tensor(0.0001)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for n_bits in [2, 4, 8, 16]:\n",
        "    res = quantize(weights, n_bits=n_bits)\n",
        "    approx_values = dequantize(*res)\n",
        "    print(f'{n_bits}-bit Quantization:')\n",
        "    print(approx_values[:6])\n",
        "    print(weights[:6])\n",
        "    print(mse_fn(approx_values, weights).sqrt())\n",
        "    print('\\n')"
      ],
      "id": "pp7G3d40a5lM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-ZR64WLa5lM"
      },
      "source": [
        "****\n",
        "**ASIDE: Weight Distribution of Phi-3's Linear Layers**\n",
        "\n",
        "The following plots show the weight distribution of a large linear layer, `qkv_proj`, within the self-\n",
        "attention block in Phi-3. Other layers, such as `o_proj`, also located within the self-attention block, and\n",
        "`gate_up_proj` and `down_proj`, in the MLP block, have very similar weight distributions. This layer is\n",
        "present in every one of the 32 decoder blocks (indicated by the number in square brackets). You’ll notice\n",
        "that these millions of weights are concentrated within a very narrow range. But there are a few outliers as\n",
        "well, so each subplot also contains the actual range of observed weights in the corresponding layer.\n",
        "\n",
        "![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/self_attn.qkv_proj.png?raw=True)\n",
        "<center>Figure 2.5 - Weight distribution of Phi-3 layers</center>\n",
        "\n",
        "****"
      ],
      "id": "M-ZR64WLa5lM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaXLr7EOa5lM"
      },
      "source": [
        "### Half-Precision Weights"
      ],
      "id": "gaXLr7EOa5lM"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "d91Gs5sFa5lM",
        "outputId": "edef5051-eca8-4101-9e6c-1fc1bb396db3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048],\n",
            "       dtype=torch.float16)\n",
            "tensor([-0.0358,  0.0720, -0.0247,  0.0086, -0.0127, -0.1048])\n"
          ]
        }
      ],
      "source": [
        "fp16_weights = weights.to(torch.float16)\n",
        "print(fp16_weights[:6])\n",
        "print(weights[:6])"
      ],
      "id": "d91Gs5sFa5lM"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "jYGKZCjWa5lM",
        "outputId": "4226d703-79d0-4b8b-df8f-a2219edb6da1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.4244e-05)\n"
          ]
        }
      ],
      "source": [
        "print(mse_fn(fp16_weights, weights).sqrt())"
      ],
      "id": "jYGKZCjWa5lM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qV1Hj1fwa5lM"
      },
      "source": [
        "#### Living on the Edge"
      ],
      "id": "qV1Hj1fwa5lM"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "02yfO9hqa5lN",
        "outputId": "4c72c0cd-51b0-4e59-b93b-927569964b71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.8526e-16)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "torch.manual_seed(14)\n",
        "tiny_values = torch.randn(1000)*1e-5\n",
        "fp16_tiny_values = tiny_values.to(torch.float16)\n",
        "mse_fn(fp16_tiny_values, tiny_values)"
      ],
      "id": "02yfO9hqa5lN"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "auyIyhtIa5lN",
        "outputId": "a3718648-de5f-484d-f145-a0b5efbd2f4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-2.7241e-06,  1.1441e-05,  3.7199e-06, -1.1252e-06, -2.4735e-08])\n",
            "tensor([-2.7418e-06,  1.1444e-05,  3.6955e-06, -1.1325e-06, -0.0000e+00],\n",
            "       dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "print(tiny_values[155:160])\n",
        "print(fp16_tiny_values[155:160])"
      ],
      "id": "auyIyhtIa5lN"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "U1s8GNrRa5lN",
        "outputId": "d71a95d7-0ed2-48b8-dc88-335a5ae7b71f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([155074.0938,  64881.6602,   2729.5815, -40790.6562,  68846.7188])\n",
            "tensor([    inf,  64896.,   2730., -40800.,     inf], dtype=torch.float16)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(19)\n",
        "large_values = torch.randn(1000)*1e5\n",
        "fp16_large_values = large_values.to(torch.float16)\n",
        "print(large_values[:5])\n",
        "print(fp16_large_values[:5])"
      ],
      "id": "U1s8GNrRa5lN"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "FX0GMzxWa5lN",
        "outputId": "d22221b1-40b3-4342-affc-5bfb8dcdaa6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "fp16_info = torch.finfo(torch.float16)\n",
        "fp16_info"
      ],
      "id": "FX0GMzxWa5lN"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1saCr5Sba5lN",
        "outputId": "30facd4f-a808-4a4e-e7b9-9c49b28021fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5.960464477539063e-08"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "smallest_subnormal = fp16_info.smallest_normal * 2**-10\n",
        "smallest_subnormal"
      ],
      "id": "1saCr5Sba5lN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgPM4X8za5lN"
      },
      "source": [
        "### The Brain Float"
      ],
      "id": "GgPM4X8za5lN"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "i1LJpTzda5lO",
        "outputId": "2ea98ec0-d587-4aa4-e15c-096e0716dc19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finfo(resolution=0.01, min=-3.38953e+38, max=3.38953e+38, eps=0.0078125, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=bfloat16)\n",
            "finfo(resolution=0.001, min=-65504, max=65504, eps=0.000976562, smallest_normal=6.10352e-05, tiny=6.10352e-05, dtype=float16)\n"
          ]
        }
      ],
      "source": [
        "bf16_info = torch.finfo(torch.bfloat16)\n",
        "print(bf16_info)\n",
        "print(fp16_info)"
      ],
      "id": "i1LJpTzda5lO"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "_dE-vRXva5lO",
        "outputId": "deabb5ab-db00-49d8-9914-f43a43d10011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "finfo(resolution=1e-06, min=-3.40282e+38, max=3.40282e+38, eps=1.19209e-07, smallest_normal=1.17549e-38, tiny=1.17549e-38, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "fp32_info = torch.finfo(torch.float32)\n",
        "fp32_info"
      ],
      "id": "_dE-vRXva5lO"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "NjFLnAcMa5lO",
        "outputId": "1e512ca0-b499-409d-b719-f1b74d8620b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.555555582])\n",
            "tensor([0.555664062], dtype=torch.float16)\n",
            "tensor([0.554687500], dtype=torch.bfloat16)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([0.555555555])\n",
        "torch.set_printoptions(precision=9)\n",
        "print(x)\n",
        "print(x.to(torch.float16))\n",
        "print(x.to(torch.bfloat16))\n",
        "torch.set_printoptions(precision=4)"
      ],
      "id": "NjFLnAcMa5lO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ciidy9cOa5lO"
      },
      "source": [
        "|Type | Precision | Sub-normal | Min. | Max. |\n",
        "|---|---|---|---|---|\n",
        "|FP32 | e-08 | e-45 | e-38 | e+38 |\n",
        "|BF16 | e-03  | NA | e-38 | e+38 |\n",
        "|FP16 | e-04  | e-08  | e-05 | e+04 |"
      ],
      "id": "Ciidy9cOa5lO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hibHexkMa5lO"
      },
      "source": [
        "### Loading Models\n",
        "\n",
        "****\n",
        "**Summary of \"Loading Models\"**\n",
        "- if supported by your GPU, use `torch.bfloat16` instead of `torch.float16` for all things 16-bit\n",
        " ```python\n",
        " supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        " dtypes16 = (torch.bfloat16 if supported else torch.float16)\n",
        " ```\n",
        "- when loading a pretrained model, always specify its `torch_dype` upfront\n",
        " ```python\n",
        " model = AutoModelForCausalLM.from_pretrained(repo_id, device_map='cuda:0', torch_dtype=torch.float32)\n",
        " ```\n",
        "****"
      ],
      "id": "hibHexkMa5lO"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "p79bmNJHa5lO"
      },
      "outputs": [],
      "source": [
        "def get_parm_dtypes(iterable, top_k=3):\n",
        "    return Counter([p.dtype for p in iterable]).most_common(top_k)"
      ],
      "id": "p79bmNJHa5lO"
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "metadata": {
        "id": "XxclJaoCrTqE",
        "outputId": "45802956-3473-4b6c-cec0-4706249d021c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XxclJaoCrTqE",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def check_devices():\n",
        "    print(\"===== 硬件设备检查 =====\")\n",
        "\n",
        "    # 检查 CPU（始终可用）\n",
        "    print(f\"CPU: 可用（默认）\")\n",
        "\n",
        "    # 检查 CUDA（NVIDIA GPU）\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"CUDA（GPU）: 可用\")\n",
        "        print(f\"GPU 数量: {torch.cuda.device_count()}\")\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            print(f\"  - GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
        "    else:\n",
        "        print(\"CUDA（GPU）: 不可用\")\n",
        "\n",
        "    # 检查 MPS（Apple Metal）\n",
        "    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
        "        print(\"MPS（Apple Metal）: 可用\")\n",
        "    else:\n",
        "        print(\"MPS（Apple Metal）: 不可用\")\n",
        "\n",
        "check_devices()"
      ],
      "metadata": {
        "id": "hVF6TWzzqQAc",
        "outputId": "6ce922ad-886a-41ee-a767-54023e7b705b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "hVF6TWzzqQAc",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== 硬件设备检查 =====\n",
            "CPU: 可用（默认）\n",
            "CUDA（GPU）: 不可用\n",
            "MPS（Apple Metal）: 不可用\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# current_device = torch.cuda.current_device()\n",
        "# print(f\"当前使用的 GPU 索引: {current_device}\")"
      ],
      "metadata": {
        "id": "7kjjZ_14rfSr"
      },
      "id": "7kjjZ_14rfSr",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "cplfbUnDa5lO",
        "outputId": "8af2299d-3e44-4241-bf75-2f0540b2a8fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324.785664\n",
            "[(torch.float32, 388)]\n",
            "cpu\n",
            "OPTForCausalLM(\n",
            "  (model): OPTModel(\n",
            "    (decoder): OPTDecoder(\n",
            "      (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
            "      (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
            "      (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
            "      (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
            "      (layers): ModuleList(\n",
            "        (0-23): 24 x OPTDecoderLayer(\n",
            "          (self_attn): OPTSdpaAttention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=50272, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", device_map='cpu')\n",
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\")\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))\n",
        "print(next(model.parameters()).device)\n",
        "print(model)"
      ],
      "id": "cplfbUnDa5lO"
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "jWPkPCnNa5lO",
        "outputId": "5d2532de-cca5-4049-e54a-85b84c367eb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-09 06:33:40--  https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.124, 18.172.134.24, 18.172.134.88, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.124|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/2d/51/2d51352256ba577724ec53b247175bd0928dfc5387e98f45a2f3eab954c26eaf/a5223ae6f3c26c6d90003f96a6bcd9a4aaaef0d36fca6469112efeeb985f2842?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1746776020&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Njc3NjAyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZC81MS8yZDUxMzUyMjU2YmE1Nzc3MjRlYzUzYjI0NzE3NWJkMDkyOGRmYzUzODdlOThmNDVhMmYzZWFiOTU0YzI2ZWFmL2E1MjIzYWU2ZjNjMjZjNmQ5MDAwM2Y5NmE2YmNkOWE0YWFhZWYwZDM2ZmNhNjQ2OTExMmVmZWViOTg1ZjI4NDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=KJ-bk2ZMXyNygtc01GMU411TekLUY1G3mrF7h5rI%7EkXkKM5IFg2Kfv9aqo1p2UW5g7SbFklHJA9vx2gVvC6FSRl83NRSlyMEZCWKv%7EDcbhxbjjC2NarDZbt2Mac9SxefFOshr6YDNPXTbmMTLLgqAyu2rJfZTEI17RynaEXi-DAueYr%7EjRjYiT7-jPnuoqOdZqFwghyotdhJmPfSDAhrfG22c5SwnGoT1rk9gblG6EpA8gFIwabuqLOjXNQHAMNpZq28c2MfoVWTeb0EEU2FXul7AesDEl0W5fuXgJ9XQR%7EikO%7EVx2Gt1lITjDsdcnqPUz1mvjURNOib16B9%7EGCnAw__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-09 06:33:40--  https://cdn-lfs.hf.co/repos/2d/51/2d51352256ba577724ec53b247175bd0928dfc5387e98f45a2f3eab954c26eaf/a5223ae6f3c26c6d90003f96a6bcd9a4aaaef0d36fca6469112efeeb985f2842?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&Expires=1746776020&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0Njc3NjAyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy8yZC81MS8yZDUxMzUyMjU2YmE1Nzc3MjRlYzUzYjI0NzE3NWJkMDkyOGRmYzUzODdlOThmNDVhMmYzZWFiOTU0YzI2ZWFmL2E1MjIzYWU2ZjNjMjZjNmQ5MDAwM2Y5NmE2YmNkOWE0YWFhZWYwZDM2ZmNhNjQ2OTExMmVmZWViOTg1ZjI4NDI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=KJ-bk2ZMXyNygtc01GMU411TekLUY1G3mrF7h5rI%7EkXkKM5IFg2Kfv9aqo1p2UW5g7SbFklHJA9vx2gVvC6FSRl83NRSlyMEZCWKv%7EDcbhxbjjC2NarDZbt2Mac9SxefFOshr6YDNPXTbmMTLLgqAyu2rJfZTEI17RynaEXi-DAueYr%7EjRjYiT7-jPnuoqOdZqFwghyotdhJmPfSDAhrfG22c5SwnGoT1rk9gblG6EpA8gFIwabuqLOjXNQHAMNpZq28c2MfoVWTeb0EEU2FXul7AesDEl0W5fuXgJ9XQR%7EikO%7EVx2Gt1lITjDsdcnqPUz1mvjURNOib16B9%7EGCnAw__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.167.152.37, 3.167.152.119, 3.167.152.106, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.167.152.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662513657 (632M) [application/octet-stream]\n",
            "Saving to: ‘pytorch_model.bin’\n",
            "\n",
            "pytorch_model.bin   100%[===================>] 631.82M  62.4MB/s    in 13s     \n",
            "\n",
            "2025-05-09 06:33:54 (47.8 MB/s) - ‘pytorch_model.bin’ saved [662513657/662513657]\n",
            "\n",
            "-rw-r--r-- 1 root root 662513657 May 11  2022 pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/facebook/opt-350m/resolve/main/pytorch_model.bin\n",
        "!ls -la pytorch_model.bin"
      ],
      "id": "jWPkPCnNa5lO"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "CnPJEDD0a5lO",
        "outputId": "487baaf2-797a-4a12-d6cd-0032e16017f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "state_dict = torch.load('pytorch_model.bin')\n",
        "get_parm_dtypes(iter(state_dict.values()))"
      ],
      "id": "CnPJEDD0a5lO"
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "xepkyr07a5lO"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             torch_dtype=torch.float32)"
      ],
      "id": "xepkyr07a5lO"
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.get_memory_footprint()/1e6)\n",
        "get_parm_dtypes(model.parameters())"
      ],
      "metadata": {
        "id": "dOkdcvhEx8uA",
        "outputId": "dbdcdd1b-774e-4e92-e62b-9e6131c4cbfb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dOkdcvhEx8uA",
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1324.785664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float32, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "JQe15oUEa5lP",
        "outputId": "8b515c25-e5a5-448d-9147-3b011d8b79da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[   2,  713,   16,   10, 2007, 1296]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}\n",
            "{'input_ids': tensor([[   2,  713,   16,   10, 2007, 1296]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]]), 'labels': tensor([[   2,  713,   16,   10, 2007, 1296]])}\n",
            "cpu\n",
            "{'input_ids': tensor([[   2,  713,   16,   10, 2007, 1296]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]]), 'labels': tensor([[   2,  713,   16,   10, 2007, 1296]])}\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "batch = tokenizer(['This is a simple test'], return_tensors='pt')\n",
        "print(batch)\n",
        "batch['labels'] = batch['input_ids']\n",
        "print(batch)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "batch = {k: v.to(device) for k, v in batch.items()}\n",
        "print(batch)"
      ],
      "id": "JQe15oUEa5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "aNF8Qoyza5lP",
        "outputId": "307adb7e-a5de-4bdd-ae6a-ed856580a1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8001, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "aNF8Qoyza5lP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsF9v6Rna5lP"
      },
      "source": [
        "#### Half-Precision Models (16-bit)"
      ],
      "id": "AsF9v6Rna5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "gB4w2rL0a5lP",
        "outputId": "10ce6895-7e19-4d4e-a2d1-ac3e44aba7e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "print(supported)\n",
        "dtype16 = (torch.bfloat16 if supported else torch.float16)\n",
        "dtype16"
      ],
      "id": "gB4w2rL0a5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "YPcVrajsa5lP",
        "outputId": "00f93e65-8477-43fd-ac6a-b7e12b8035fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662.392832\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(torch.float16, 388)]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ],
      "source": [
        "model.to(dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "get_parm_dtypes(model.parameters())"
      ],
      "id": "YPcVrajsa5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "ixgRso_la5lP",
        "outputId": "3087852c-89a4-455b-bc26-2359babce60a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "662.392832\n",
            "[(torch.float16, 388)]\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                             torch_dtype=dtype16)\n",
        "print(model.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model.parameters()))"
      ],
      "id": "ixgRso_la5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "VypS3fDTa5lP",
        "outputId": "6d0b2509-ced8-4f7a-b522-a452e92da0d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8000, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "out = model(**batch)\n",
        "out.loss"
      ],
      "id": "VypS3fDTa5lP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFX48WRUa5lP"
      },
      "source": [
        "### Mixed Precision"
      ],
      "id": "mFX48WRUa5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "2D3vqwY_a5lP"
      },
      "outputs": [],
      "source": [
        "class MixedModel(nn.Module):\n",
        "    def __init__(self, dtype):\n",
        "        super().__init__()\n",
        "        self.a = nn.Linear(1000, 1000, dtype=dtype)\n",
        "        self.b = nn.Linear(1000, 1000, dtype=dtype)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.b(self.a(x))"
      ],
      "id": "2D3vqwY_a5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "aOx_mYGYa5lP"
      },
      "outputs": [],
      "source": [
        "mixed32 = MixedModel(torch.float32)\n"
      ],
      "id": "aOx_mYGYa5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "h4kLaBYWa5lP",
        "outputId": "09e9b0d4-ad60-4173-9e23-0fef5891c832",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71.6 ms ± 821 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32))"
      ],
      "id": "h4kLaBYWa5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "JINhBj_ga5lP"
      },
      "outputs": [],
      "source": [
        "mixed16 = MixedModel(torch.float16)"
      ],
      "id": "JINhBj_ga5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "ojxjj6nva5lP",
        "outputId": "2621da56-d53f-4c16-be20-f16838ba6d40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "712 ms ± 72.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed16(torch.randn(1000, 1000, dtype=torch.float16))"
      ],
      "id": "ojxjj6nva5lP"
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "w698u82ca5lQ",
        "outputId": "f8c59ab3-0fa5-4d56-a3c4-cb6f39868446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "877 ms ± 158 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "with torch.autocast(device_type=\"cpu\", dtype=torch.float16):\n",
        "    %timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cpu'))"
      ],
      "id": "w698u82ca5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "4NJhwchDa5lQ"
      },
      "outputs": [],
      "source": [
        "with torch.autocast(device_type=\"cpu\", dtype=torch.float16):\n",
        "    res16 = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cpu'))\n",
        "\n",
        "res32 = res16.float()"
      ],
      "id": "4NJhwchDa5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "qLIvnoCZa5lQ"
      },
      "outputs": [],
      "source": [
        "autocast_context = torch.autocast(device_type=\"cpu\", dtype=torch.float16)\n",
        "# original forward method\n",
        "model_forward_func = mixed32.forward.__func__\n",
        "# wrapping the method with the context manager\n",
        "new_forward = autocast_context(model_forward_func)\n",
        "# assigning the wrapped method back to the model\n",
        "mixed32.forward = MethodType(new_forward, mixed32)"
      ],
      "id": "qLIvnoCZa5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "3uvkuNlga5lQ",
        "outputId": "097f4ceb-a830-45f5-82bf-58318ff874c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cpu'))\n",
        "res.dtype"
      ],
      "id": "3uvkuNlga5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "mVUEzaCUa5lQ"
      },
      "outputs": [],
      "source": [
        "mixed32.forward = MethodType(convert_outputs_to_fp32(mixed32.forward.__func__), mixed32)"
      ],
      "id": "mVUEzaCUa5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "guyxP2Xia5lQ",
        "outputId": "851982fd-8aa7-4aab-d855-f1b3705f0bf6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "res = mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cpu'))\n",
        "res.dtype"
      ],
      "id": "guyxP2Xia5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "wKlkTPtAa5lQ",
        "outputId": "7fd054a0-cd25-446b-edb1-38621ec5c366",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "533 ms ± 95.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%timeit mixed32(torch.randn(1000, 1000, dtype=torch.float32, device='cpu'))"
      ],
      "id": "wKlkTPtAa5lQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFZ01TaSa5lQ"
      },
      "source": [
        "### BitsAndBytes\n",
        "\n",
        "[BitsAndBytes](https://huggingface.co/docs/bitsandbytes/main/en/index) is your go-to package for quantization. From its documentation:\n",
        "\n",
        "\"_bitsandbytes enables accessible large language models via k-bit quantization for PyTorch. bitsandbytes provides three main features for dramatically reducing memory consumption for inference and training:_\n",
        "\n",
        "- _8-bit optimizers uses block-wise quantization to maintain 32-bit performance at a small fraction of the memory cost._\n",
        "- _LLM.Int() or 8-bit quantization enables large language model inference with only half the required memory and without any performance degradation. This method is based on vector-wise quantization to quantize most features to 8-bits and separately treating outliers with 16-bit matrix multiplication._\n",
        "- _QLoRA or 4-bit quantization enables large language model training with several memory-saving techniques that don’t compromise performance. This method quantizes a model to 4-bits and inserts a small set of trainable low-rank adaptation (LoRA) weights to allow training._\""
      ],
      "id": "pFZ01TaSa5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "scrolled": true,
        "id": "a4CY089Ia5lQ",
        "outputId": "ffa30f63-f583-40ec-d2c5-e692ec25aca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BitsAndBytesConfig {\n",
              "  \"_load_in_4bit\": false,\n",
              "  \"_load_in_8bit\": false,\n",
              "  \"bnb_4bit_compute_dtype\": \"float32\",\n",
              "  \"bnb_4bit_quant_storage\": \"uint8\",\n",
              "  \"bnb_4bit_quant_type\": \"fp4\",\n",
              "  \"bnb_4bit_use_double_quant\": false,\n",
              "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
              "  \"llm_int8_has_fp16_weight\": false,\n",
              "  \"llm_int8_skip_modules\": null,\n",
              "  \"llm_int8_threshold\": 6.0,\n",
              "  \"load_in_4bit\": false,\n",
              "  \"load_in_8bit\": false,\n",
              "  \"quant_method\": \"bitsandbytes\"\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ],
      "source": [
        "bnb_config = BitsAndBytesConfig()\n",
        "bnb_config"
      ],
      "id": "a4CY089Ia5lQ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5aNukqd7uTb"
      },
      "id": "k5aNukqd7uTb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13CvR6BJa5lQ"
      },
      "source": [
        "#### 8-Bit Quantization\n",
        "\n",
        "\"_LLM.int8() is a quantization method that doesn’t degrade performance which makes large model inference more accessible. The key is to extract the outliers from the inputs and weights and multiply them in 16-bit. All other values are multiplied in 8-bit and quantized to Int8 before being dequantized back to 16-bits. The outputs from the 16-bit and 8-bit multiplication are combined to produce the final output._\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)\n",
        "\n",
        "****\n",
        "**Summary of \"8-Bit Quantization\"**\n",
        "- load an 8-bit quantized model in a few lines of code:\n",
        "  ```python\n",
        "    bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                                 device_map='cuda:0',\n",
        "                                                 torch_dtype=torch.float32,\n",
        "                                                 quantization_config=bnb_config)\n",
        "  ```\n",
        "  - quantization modifies the default type of non-quantized layers to `torch.float16` unless we actively provide the `torch_dtype` argument when calling the `from_pretrained()` method\n",
        "- 8-bit quantization replaces all linear layers except for:\n",
        "  - layers with tied (shared) weights\n",
        "  - the last layer in the model\n",
        "  - any layer named `lm_head`\n",
        "- if you want to skip additional modules, use the `llm_int8_skip_modules` configuration argument and make sure to manually include the layers with tied (shared) weights to avoid errors\n",
        "- computation (inside the quantized layers) happens in `torch.float16`\n",
        "****"
      ],
      "id": "13CvR6BJa5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtSeSlQea5lQ",
        "outputId": "dd3adb6f-a9eb-4b1c-dbf7-878070ea7594"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "359.354368\n",
            "[(torch.float16, 242), (torch.int8, 146)]\n"
          ]
        }
      ],
      "source": [
        "bnb_config_q8 = BitsAndBytesConfig(load_in_8bit=True)\n",
        "model_q8 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8)\n",
        "print(model_q8.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8.parameters()))"
      ],
      "id": "CtSeSlQea5lQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5ZrB3C7a5lR",
        "outputId": "b4ccdfbb-8e30-4b6d-97fd-80517c64dcd1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(nan, device='cuda:0', dtype=torch.float16, grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# you may not get a NaN back, as it depends on the environment\n",
        "out = model_q8(**batch)\n",
        "out.loss"
      ],
      "id": "o5ZrB3C7a5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9w35voKya5lR",
        "outputId": "bc497005-8a34-4a9f-f40e-9e7cddb71868"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "415.670272\n",
            "[(torch.float32, 242), (torch.int8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q8_32 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                quantization_config=bnb_config_q8,\n",
        "                                                torch_dtype=torch.float32)\n",
        "print(model_q8_32.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q8_32.parameters()))"
      ],
      "id": "9w35voKya5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cayIiy0la5lR",
        "outputId": "3cf13384-b198-409f-af88-466675db14e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(3.8024, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model_q8_32(**batch)\n",
        "out.loss"
      ],
      "id": "cayIiy0la5lR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6OzsJ30a5lR"
      },
      "source": [
        "##### Quantized Linear Layers"
      ],
      "id": "a6OzsJ30a5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srVFauxja5lR",
        "outputId": "073bc6ba-4279-42a3-875d-22dcf77db988"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear8bitLt(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear8bitLt(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear8bitLt(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_layer = model_q8_32.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "srVFauxja5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3f6_qhta5lR",
        "outputId": "6e771fc8-fc27-41a3-c538-ecfdef0fad55"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear8bitLt(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q8_layer = dec_layer.self_attn.k_proj\n",
        "q8_layer"
      ],
      "id": "g3f6_qhta5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwALba6ra5lR",
        "outputId": "70f4d909-cc84-49e3-8912-04020a0a5198"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -67, -113,  -89,  ...,   65,  -16,  -87],\n",
              "                      [  60,  120,   90,  ...,  -50,   32,   80],\n",
              "                      [  47,  127,   86,  ...,  -34,    8,   90],\n",
              "                      ...,\n",
              "                      [ -65,   65,   34,  ...,  -64,   35,   64],\n",
              "                      [  57,   67,   21,  ...,   63,  -64,  -64],\n",
              "                      [ -64,   63,  -11,  ...,  -64,   34,   63]], device='cuda:0',\n",
              "                     dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.1250, 0.1252, 0.1250,  ..., 0.1252, 0.1250, 0.1254], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q8_state = q8_layer.state_dict()\n",
        "q8_state"
      ],
      "id": "vwALba6ra5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHoBw_k2a5lR",
        "outputId": "6837673a-d70b-4e13-ef4a-968135b1c3e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding(50272, 512, padding_idx=1)\n",
            "Linear(in_features=512, out_features=50272, bias=False)\n"
          ]
        }
      ],
      "source": [
        "print(model.model.decoder.embed_tokens)\n",
        "print(model.lm_head)"
      ],
      "id": "LHoBw_k2a5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IqvKn2Wta5lR",
        "outputId": "b62f6412-7a56-4721-ee03-f573ca5de204"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.allclose(model.model.decoder.embed_tokens.weight,\n",
        "               model.lm_head.weight)"
      ],
      "id": "IqvKn2Wta5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EixEYIUUa5lR",
        "outputId": "925c3655-ffc0-4f1c-97d3-207efa2f64d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(True, [['lm_head.weight', 'model.decoder.embed_tokens.weight']])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained('facebook/opt-350m')\n",
        "\n",
        "config.tie_word_embeddings, find_tied_parameters(model)"
      ],
      "id": "EixEYIUUa5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGrbY5EAa5lR",
        "outputId": "45ac8289-ba82-46de-c715-5c3c6e84a67a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor(..., device='meta', size=(50272, 512), requires_grad=True)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with init_empty_weights(): # loads meta tensors only\n",
        "    empty_model = AutoModelForCausalLM.from_config(config)\n",
        "\n",
        "empty_model.lm_head.weight"
      ],
      "id": "xGrbY5EAa5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEYtyjE6a5lR",
        "outputId": "93bd9dfa-8e4a-4768-9183-22d5ad3f93f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['lm_head', 'model.decoder.embed_tokens']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "skip_modules = get_keys_to_not_convert(empty_model)\n",
        "skip_modules"
      ],
      "id": "LEYtyjE6a5lR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTRbKRXHa5lR",
        "outputId": "cf89f18e-5906-4111-c98b-4e8a65de04f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "lm_head: torch.float32\n",
            "model.decoder.embed_tokens: torch.float32\n"
          ]
        }
      ],
      "source": [
        "for module in skip_modules:\n",
        "    print(f'{module}: {next(model_q8_32.get_submodule(module).parameters()).dtype}')"
      ],
      "id": "MTRbKRXHa5lR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI26oBxMa5lR"
      },
      "source": [
        "#### `llm_int8_skip_modules`\n",
        "\n",
        "If your model has tied weights, and you choose to use your own list of modules to skip, you\n",
        "must add one of the tied layers to your list. If you don’t, you may get the following\n",
        "exception:\n",
        "\n",
        "***\n",
        "`AttributeError: 'Parameter' object has no attribute 'SCB'`\n",
        "***\n",
        "\n",
        "```python\n",
        "# This configuration WILL raise an exception\n",
        "# while trying to load weights for the tied layer\n",
        "# bnb_config_skip = BitsAndBytesConfig(load_in_8bit=True,\n",
        "#                                      llm_int8_skip_modules=['o_proj'])\n",
        "\n",
        "# This configuration works fine because\n",
        "# the tied layer, lm_head, is in the list\n",
        "bnb_config_skip = BitsAndBytesConfig(\n",
        "        load_in_8bit=True,\n",
        "        llm_int8_skip_modules=['o_proj', 'lm_head'])\n",
        "\n",
        "model_skip = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                  device_map='cuda:0',\n",
        "                                                  torch_dtype=torch.float32,\n",
        "                                                  quantization_config=bnb_config_skip)\n",
        "```"
      ],
      "id": "bI26oBxMa5lR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HOSKlpva5lS"
      },
      "source": [
        "##### 8-bit Layers\n",
        "\n",
        "\"*In order to quantize a linear layer one should first load the original fp16 / bf16 weights into the Linear8bitLt module, then call int8_module.to(\"cuda\") to quantize the fp16 weights.*\"\n",
        "\n",
        "Source: [8-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear8bit)"
      ],
      "id": "7HOSKlpva5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8DAu-CJa5lS",
        "outputId": "92b996c1-8e24-401b-ec51-77e592e43e85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[-0.2220, -0.0085,  0.3072, -0.2097,  0.0531,  0.1224,  0.0525, -0.2350,\n",
              "                        0.0456,  0.2687],\n",
              "                      [-0.1459,  0.1786, -0.1443, -0.0233,  0.1689,  0.0015, -0.2514,  0.1644,\n",
              "                        0.1920,  0.1678],\n",
              "                      [ 0.2346,  0.1411,  0.2128,  0.0519,  0.2147, -0.2786, -0.0433, -0.0364,\n",
              "                       -0.1504,  0.0823],\n",
              "                      [ 0.2388, -0.2134, -0.1620, -0.1023,  0.2433, -0.2680,  0.3099, -0.1933,\n",
              "                       -0.0471, -0.0391],\n",
              "                      [-0.1273,  0.2197, -0.0136, -0.1938, -0.1746,  0.0404,  0.0711, -0.1730,\n",
              "                        0.0539, -0.1992],\n",
              "                      [-0.0051,  0.1373, -0.0267, -0.0907, -0.0107,  0.1108, -0.1566,  0.0172,\n",
              "                        0.2075, -0.0028],\n",
              "                      [ 0.2082, -0.2857, -0.2640, -0.1436,  0.1704,  0.1908, -0.2350,  0.1187,\n",
              "                       -0.0568,  0.0916],\n",
              "                      [ 0.2974, -0.3061,  0.0559,  0.1899,  0.0265, -0.1893, -0.0582, -0.0943,\n",
              "                        0.2451,  0.2825],\n",
              "                      [-0.1241, -0.3106, -0.1002, -0.1745,  0.2693,  0.2985,  0.1633, -0.0270,\n",
              "                       -0.3049,  0.0227],\n",
              "                      [-0.1217,  0.0035, -0.1481, -0.0330,  0.1787,  0.3123,  0.2600, -0.1720,\n",
              "                        0.2059,  0.2057]])),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854]))])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "\n",
        "torch.manual_seed(11)\n",
        "fp_layer = nn.Linear(n_in, n_out)\n",
        "\n",
        "int8_layer = Linear8bitLt(n_in, n_out, has_fp16_weights=False)\n",
        "\n",
        "int8_layer.load_state_dict(fp_layer.state_dict())\n",
        "int8_layer.state_dict()"
      ],
      "id": "w8DAu-CJa5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37Wat9EKa5lS",
        "outputId": "35afb889-72f8-4a32-ff6f-e84bf6c2a36a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ -92,   -4,  127,  -87,   22,   51,   22,  -97,   19,  111],\n",
              "                      [ -74,   90,  -73,  -12,   85,    1, -127,   83,   97,   85],\n",
              "                      [ 107,   64,   97,   24,   98, -127,  -20,  -17,  -69,   38],\n",
              "                      [  98,  -87,  -66,  -42,  100, -110,  127,  -79,  -19,  -16],\n",
              "                      [ -74,  127,   -8, -112, -101,   23,   41, -100,   31, -115],\n",
              "                      [  -3,   84,  -16,  -56,   -7,   68,  -96,   11,  127,   -2],\n",
              "                      [  93, -127, -117,  -64,   76,   85, -104,   53,  -25,   41],\n",
              "                      [ 123, -127,   23,   79,   11,  -79,  -24,  -39,  102,  117],\n",
              "                      [ -51, -127,  -41,  -71,  110,  122,   67,  -11, -125,    9],\n",
              "                      [ -50,    1,  -60,  -13,   73,  127,  106,  -70,   84,   84]],\n",
              "                     device='cuda:0', dtype=torch.int8)),\n",
              "             ('bias',\n",
              "              tensor([ 0.1269,  0.2999,  0.0252, -0.0380, -0.1788, -0.0704,  0.1124, -0.2233,\n",
              "                       0.0653, -0.0854], device='cuda:0')),\n",
              "             ('SCB',\n",
              "              tensor([0.3071, 0.2515, 0.2786, 0.3098, 0.2197, 0.2075, 0.2856, 0.3062, 0.3105,\n",
              "                      0.3123], device='cuda:0')),\n",
              "             ('weight_format', tensor(0, dtype=torch.uint8))])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int8_layer = int8_layer.to(0) # Quantization happens here\n",
        "int8_state = int8_layer.state_dict()\n",
        "int8_state"
      ],
      "id": "37Wat9EKa5lS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vL6WjnCa5lS"
      },
      "source": [
        "#### 4-bit Quantization\n",
        "\n",
        "\"*QLoRA is a finetuning method that quantizes a model to 4-bits and adds a set of low-rank adaptation (LoRA) weights to the model and tuning them through the quantized weights. This method also introduces a new data type, 4-bit NormalFloat (LinearNF4) in addition to the standard Float4 data type (LinearFP4). LinearNF4 is a quantization data type for normally distributed data and can improve performance.*\"\n",
        "\n",
        "Source: [4-bit quantization](https://huggingface.co/docs/bitsandbytes/en/reference/nn/linear4bit)\n",
        "\n",
        "****\n",
        "**Summary of \"4-Bit Quantization\"**\n",
        "- squeeze the most of a 4-bit quantized model by using the normal float (NF4) type and double quantization\n",
        "  ```python\n",
        "  supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "  compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "  nf4_config = BitsAndBytesConfig(\n",
        "     load_in_4bit=True,\n",
        "     bnb_4bit_quant_type=\"nf4\",\n",
        "     bnb_4bit_use_double_quant=True,\n",
        "     bnb_4bit_compute_dtype=compute_dtype\n",
        "  )\n",
        "  model = AutoModelForCausalLM.from_pretrained(repo_id,\n",
        "                                               device_map='cuda:0',\n",
        "                                               torch_dtype=torch.float32,\n",
        "                                               quantization_config=nf4_config)\n",
        "  ```\n",
        "- computation happens (inside the quantized layers) in the specified type (`bnb_4bit_compute_dtype`):\n",
        "FP32 is better than BF16, which is better than FP16.\n",
        "****"
      ],
      "id": "-vL6WjnCa5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2rYeA6ta5lS"
      },
      "outputs": [],
      "source": [
        "supported = torch.cuda.is_bf16_supported(including_emulation=False)\n",
        "compute_dtype = (torch.bfloat16 if supported else torch.float32)\n",
        "\n",
        "nf4_config = BitsAndBytesConfig(\n",
        "   load_in_4bit=True,\n",
        "   bnb_4bit_quant_type=\"nf4\",\n",
        "   bnb_4bit_use_double_quant=True,\n",
        "   bnb_4bit_compute_dtype=compute_dtype\n",
        ")"
      ],
      "id": "p2rYeA6ta5lS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu7OQO7Ya5lS"
      },
      "source": [
        "**The Secret Lives of `Dtypes`**\n",
        "\n",
        "| Regular Model | Quantized Model |\n",
        "|---|---|\n",
        "| ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_regular.png?raw=True) | ![](https://github.com/dvgodoy/FineTuningLLMs/blob/main/images/ch2/type_flow_qt.png?raw=True) |\n",
        "| <center>Figure 2.6 - Data types flowing through a regular model</center> | <center>Figure 2.7 - Data types flowing through a quantized model</center> |"
      ],
      "id": "Fu7OQO7Ya5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kHaDuP4Ca5lS",
        "outputId": "b6496f22-f7e9-4dde-9d89-99a8cdede260"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "264.15104\n",
            "[(torch.float32, 242), (torch.uint8, 146)]\n"
          ]
        }
      ],
      "source": [
        "model_q4 = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\",\n",
        "                                                device_map='cuda:0',\n",
        "                                                torch_dtype=torch.float32,\n",
        "                                                quantization_config=nf4_config)\n",
        "print(model_q4.get_memory_footprint()/1e6)\n",
        "print(get_parm_dtypes(model_q4.parameters()))"
      ],
      "id": "kHaDuP4Ca5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V982H_CCa5lS",
        "outputId": "569b3380-8606-4918-c4ba-82266593e267"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(4.7016, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out = model_q4(**batch)\n",
        "out.loss"
      ],
      "id": "V982H_CCa5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo8a2l-Ra5lS",
        "outputId": "a1b65e96-d65c-48f9-de39-9259b68e98f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OPTDecoderLayer(\n",
              "  (self_attn): OPTAttention(\n",
              "    (k_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (v_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (q_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "    (out_proj): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
              "  )\n",
              "  (activation_fn): ReLU()\n",
              "  (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  (fc1): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
              "  (fc2): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
              "  (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dec_layer = model_q4.model.decoder.layers[0]\n",
        "dec_layer"
      ],
      "id": "zo8a2l-Ra5lS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Gxh_4dCa5lT",
        "outputId": "70ee394b-53ee-4b08-f420-6f4e9e0d57b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Linear4bit(in_features=1024, out_features=1024, bias=True)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q4_layer = dec_layer.self_attn.k_proj\n",
        "q4_layer"
      ],
      "id": "6Gxh_4dCa5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Rz6fN1Xa5lT",
        "outputId": "c52dd8cf-4856-4989-f056-9cf138e37e65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[ 32],\n",
              "                      [ 29],\n",
              "                      [208],\n",
              "                      ...,\n",
              "                      [ 66],\n",
              "                      [ 34],\n",
              "                      [172]], device='cuda:0', dtype=torch.uint8)),\n",
              "             ('bias',\n",
              "              tensor([-0.0134,  0.0082,  0.0161,  ..., -0.0242, -0.0150,  0.0203],\n",
              "                     device='cuda:0', dtype=torch.float16)),\n",
              "             ('weight.absmax',\n",
              "              tensor([230, 230,  30,  ...,   1,  26, 191], device='cuda:0',\n",
              "                     dtype=torch.uint8)),\n",
              "             ('weight.quant_map',\n",
              "              tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "                       0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "                     device='cuda:0')),\n",
              "             ('weight.nested_absmax',\n",
              "              tensor([0.0077, 0.0142, 0.0153, 0.0138, 0.0399, 0.0409, 0.0417, 0.0426, 0.0053,\n",
              "                      0.0053, 0.0053, 0.0053, 0.0051, 0.0051, 0.0051, 0.0053, 0.0195, 0.0269,\n",
              "                      0.0223, 0.0195, 0.0053, 0.0053, 0.0054, 0.0054, 0.0317, 0.0315, 0.0306,\n",
              "                      0.0320, 0.0262, 0.0265, 0.0230, 0.0296, 0.0051, 0.0065, 0.0050, 0.0050,\n",
              "                      0.0051, 0.0053, 0.0050, 0.0051, 0.0056, 0.0056, 0.0056, 0.0056, 0.0428,\n",
              "                      0.0410, 0.0405, 0.0422, 0.0397, 0.0402, 0.0394, 0.0414, 0.0204, 0.0106,\n",
              "                      0.0140, 0.0078, 0.0406, 0.0349, 0.0359, 0.0418, 0.0503, 0.0499, 0.0470,\n",
              "                      0.0458], device='cuda:0')),\n",
              "             ('weight.nested_quant_map',\n",
              "              tensor([-9.9297e-01, -9.7891e-01, -9.6484e-01, -9.5078e-01, -9.3672e-01,\n",
              "                      -9.2266e-01, -9.0859e-01, -8.9453e-01, -8.8047e-01, -8.6641e-01,\n",
              "                      -8.5234e-01, -8.3828e-01, -8.2422e-01, -8.1016e-01, -7.9609e-01,\n",
              "                      -7.8203e-01, -7.6797e-01, -7.5391e-01, -7.3984e-01, -7.2578e-01,\n",
              "                      -7.1172e-01, -6.9766e-01, -6.8359e-01, -6.6953e-01, -6.5547e-01,\n",
              "                      -6.4141e-01, -6.2734e-01, -6.1328e-01, -5.9922e-01, -5.8516e-01,\n",
              "                      -5.7109e-01, -5.5703e-01, -5.4297e-01, -5.2891e-01, -5.1484e-01,\n",
              "                      -5.0078e-01, -4.8672e-01, -4.7266e-01, -4.5859e-01, -4.4453e-01,\n",
              "                      -4.3047e-01, -4.1641e-01, -4.0234e-01, -3.8828e-01, -3.7422e-01,\n",
              "                      -3.6016e-01, -3.4609e-01, -3.3203e-01, -3.1797e-01, -3.0391e-01,\n",
              "                      -2.8984e-01, -2.7578e-01, -2.6172e-01, -2.4766e-01, -2.3359e-01,\n",
              "                      -2.1953e-01, -2.0547e-01, -1.9141e-01, -1.7734e-01, -1.6328e-01,\n",
              "                      -1.4922e-01, -1.3516e-01, -1.2109e-01, -1.0703e-01, -9.8594e-02,\n",
              "                      -9.5781e-02, -9.2969e-02, -9.0156e-02, -8.7344e-02, -8.4531e-02,\n",
              "                      -8.1719e-02, -7.8906e-02, -7.6094e-02, -7.3281e-02, -7.0469e-02,\n",
              "                      -6.7656e-02, -6.4844e-02, -6.2031e-02, -5.9219e-02, -5.6406e-02,\n",
              "                      -5.3594e-02, -5.0781e-02, -4.7969e-02, -4.5156e-02, -4.2344e-02,\n",
              "                      -3.9531e-02, -3.6719e-02, -3.3906e-02, -3.1094e-02, -2.8281e-02,\n",
              "                      -2.5469e-02, -2.2656e-02, -1.9844e-02, -1.7031e-02, -1.4219e-02,\n",
              "                      -1.1406e-02, -9.7187e-03, -9.1562e-03, -8.5938e-03, -8.0312e-03,\n",
              "                      -7.4687e-03, -6.9063e-03, -6.3437e-03, -5.7813e-03, -5.2188e-03,\n",
              "                      -4.6562e-03, -4.0937e-03, -3.5312e-03, -2.9687e-03, -2.4062e-03,\n",
              "                      -1.8438e-03, -1.2812e-03, -9.4375e-04, -8.3125e-04, -7.1875e-04,\n",
              "                      -6.0625e-04, -4.9375e-04, -3.8125e-04, -2.6875e-04, -1.5625e-04,\n",
              "                      -8.8750e-05, -6.6250e-05, -4.3750e-05, -2.1250e-05, -7.7500e-06,\n",
              "                      -3.2500e-06, -5.5000e-07,  0.0000e+00,  5.5000e-07,  3.2500e-06,\n",
              "                       7.7500e-06,  2.1250e-05,  4.3750e-05,  6.6250e-05,  8.8750e-05,\n",
              "                       1.5625e-04,  2.6875e-04,  3.8125e-04,  4.9375e-04,  6.0625e-04,\n",
              "                       7.1875e-04,  8.3125e-04,  9.4375e-04,  1.2812e-03,  1.8438e-03,\n",
              "                       2.4062e-03,  2.9687e-03,  3.5312e-03,  4.0937e-03,  4.6562e-03,\n",
              "                       5.2188e-03,  5.7813e-03,  6.3437e-03,  6.9063e-03,  7.4687e-03,\n",
              "                       8.0312e-03,  8.5938e-03,  9.1562e-03,  9.7187e-03,  1.1406e-02,\n",
              "                       1.4219e-02,  1.7031e-02,  1.9844e-02,  2.2656e-02,  2.5469e-02,\n",
              "                       2.8281e-02,  3.1094e-02,  3.3906e-02,  3.6719e-02,  3.9531e-02,\n",
              "                       4.2344e-02,  4.5156e-02,  4.7969e-02,  5.0781e-02,  5.3594e-02,\n",
              "                       5.6406e-02,  5.9219e-02,  6.2031e-02,  6.4844e-02,  6.7656e-02,\n",
              "                       7.0469e-02,  7.3281e-02,  7.6094e-02,  7.8906e-02,  8.1719e-02,\n",
              "                       8.4531e-02,  8.7344e-02,  9.0156e-02,  9.2969e-02,  9.5781e-02,\n",
              "                       9.8594e-02,  1.0703e-01,  1.2109e-01,  1.3516e-01,  1.4922e-01,\n",
              "                       1.6328e-01,  1.7734e-01,  1.9141e-01,  2.0547e-01,  2.1953e-01,\n",
              "                       2.3359e-01,  2.4766e-01,  2.6172e-01,  2.7578e-01,  2.8984e-01,\n",
              "                       3.0391e-01,  3.1797e-01,  3.3203e-01,  3.4609e-01,  3.6016e-01,\n",
              "                       3.7422e-01,  3.8828e-01,  4.0234e-01,  4.1641e-01,  4.3047e-01,\n",
              "                       4.4453e-01,  4.5859e-01,  4.7266e-01,  4.8672e-01,  5.0078e-01,\n",
              "                       5.1484e-01,  5.2891e-01,  5.4297e-01,  5.5703e-01,  5.7109e-01,\n",
              "                       5.8516e-01,  5.9922e-01,  6.1328e-01,  6.2734e-01,  6.4141e-01,\n",
              "                       6.5547e-01,  6.6953e-01,  6.8359e-01,  6.9766e-01,  7.1172e-01,\n",
              "                       7.2578e-01,  7.3984e-01,  7.5391e-01,  7.6797e-01,  7.8203e-01,\n",
              "                       7.9609e-01,  8.1016e-01,  8.2422e-01,  8.3828e-01,  8.5234e-01,\n",
              "                       8.6641e-01,  8.8047e-01,  8.9453e-01,  9.0859e-01,  9.2266e-01,\n",
              "                       9.3672e-01,  9.5078e-01,  9.6484e-01,  9.7891e-01,  9.9297e-01,\n",
              "                       1.0000e+00], device='cuda:0')),\n",
              "             ('weight.quant_state.bitsandbytes__nf4',\n",
              "              tensor([123,  34, 113, 117,  97, 110, 116,  95, 116, 121, 112, 101,  34,  58,\n",
              "                       32,  34, 110, 102,  52,  34,  44,  32,  34,  98, 108, 111,  99, 107,\n",
              "                      115, 105, 122, 101,  34,  58,  32,  54,  52,  44,  32,  34, 100, 116,\n",
              "                      121, 112, 101,  34,  58,  32,  34, 102, 108, 111,  97, 116,  49,  54,\n",
              "                       34,  44,  32,  34, 115, 104,  97, 112, 101,  34,  58,  32,  91,  49,\n",
              "                       48,  50,  52,  44,  32,  49,  48,  50,  52,  93,  44,  32,  34, 110,\n",
              "                      101, 115, 116, 101, 100,  95,  98, 108, 111,  99, 107, 115, 105, 122,\n",
              "                      101,  34,  58,  32,  50,  53,  54,  44,  32,  34, 110, 101, 115, 116,\n",
              "                      101, 100,  95, 100, 116, 121, 112, 101,  34,  58,  32,  34, 102, 108,\n",
              "                      111,  97, 116,  51,  50,  34,  44,  32,  34, 110, 101, 115, 116, 101,\n",
              "                      100,  95, 111, 102, 102, 115, 101, 116,  34,  58,  32,  48,  46,  49,\n",
              "                       49,  57,  57,  56,  49,  55,  50,  49,  48,  52,  51,  53,  56,  54,\n",
              "                       55,  51, 125], dtype=torch.uint8))])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "q4_layer.state_dict()"
      ],
      "id": "2Rz6fN1Xa5lT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3beSrJqa5lT"
      },
      "source": [
        "##### FP4 vs NF4 Layers"
      ],
      "id": "l3beSrJqa5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu4vnCyUa5lT",
        "outputId": "9532c7b3-e5af-4d9f-832e-e1b2165b6c35"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Linear(in_features=10, out_features=10, bias=True)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_in = 10\n",
        "n_out = 10\n",
        "torch.manual_seed(11)\n",
        "fp16_layer = nn.Linear(n_in, n_out)\n",
        "fp16_layer"
      ],
      "id": "yu4vnCyUa5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8ChZm7Ia5lT",
        "outputId": "2c7cd25a-e024-48cb-a3b5-222c2af65c0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp4_layer = LinearFP4(n_in, n_out)\n",
        "fp4_layer.load_state_dict(fp16_layer.state_dict())\n",
        "\n",
        "nf4_model = LinearNF4(n_in, n_out)\n",
        "nf4_model.load_state_dict(fp16_layer.state_dict())"
      ],
      "id": "v8ChZm7Ia5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4XtpcnOa5lT",
        "outputId": "1ac9110f-d6c2-4f18-e82d-95891f6cd92f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 0.0000,  0.0052,  0.6667,  1.0000,  0.3333,  0.5000,  0.1667,  0.2500,\n",
              "          0.0000, -0.0052, -0.6667, -1.0000, -0.3333, -0.5000, -0.1667, -0.2500],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fp4_layer = fp4_layer.to(0) # Quantization happens here\n",
        "fp4_state = fp4_layer.state_dict()\n",
        "\n",
        "fp4_state['weight.quant_map'], fp4_state['weight'].shape"
      ],
      "id": "I4XtpcnOa5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeZn5H7ia5lT",
        "outputId": "df4a4c0d-d636-47a6-e927-9f18783f0dda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'FP4 quantization')"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(fp4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('FP4 quantization')"
      ],
      "id": "JeZn5H7ia5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRQwPalca5lT",
        "outputId": "8ccf0502-f0bc-4238-e4c5-908d7ff518c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([-1.0000, -0.6962, -0.5251, -0.3949, -0.2844, -0.1848, -0.0911,  0.0000,\n",
              "          0.0796,  0.1609,  0.2461,  0.3379,  0.4407,  0.5626,  0.7230,  1.0000],\n",
              "        device='cuda:0'),\n",
              " torch.Size([50, 1]))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nf4_model = nf4_model.to(0) # Quantization happens here\n",
        "nf4_state = nf4_model.state_dict()\n",
        "\n",
        "nf4_state['weight.quant_map'], nf4_state['weight'].shape"
      ],
      "id": "yRQwPalca5lT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gimZ4RTia5lT",
        "outputId": "9efc2f07-80ce-4dfd-a461-ecba815e4a95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'NF4 quantization')"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAABoCAYAAADPaejQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaT0lEQVR4nO3de1xUdf4/8NdwG64zQIBIIgIaKhfx8gDlkeEqJYXlZdvUUmFTUreVTDHFFEQrcTW3Hq6luIhutrLparqbWrorD7VI0tBU1AXEGyqmKKB4YYb3749+c74cZ4CZYeZwxt7Px4PHw/mcz3l/Pu/5eOY9l3NmFEREYIwxxliHs+voCTDGGGPsF1yUGWOMMZngoswYY4zJBBdlxhhjTCa4KDPGGGMywUWZMcYYkwkuyowxxphMcFFmjDHGZIKLMmOMMSYTXJQZYwCARYsWQaFQ/GrGZUyOuCgzm7NhwwYoFAo4OzujqqpKb/uQIUMQEREhauvWrRsUCoXBv/v37xsc5/3334dCodCLZcsaGhqwaNEiFBYW/irGZczWOHT0BBgz14MHD5CTk4NVq1YZ1T86OhqzZ8/Wa3dyctJru3z5Mj744AO4ubm1e55y0tDQgOzsbAC/PHlpbsGCBZg3b95jNS5jtoaLMrNZ0dHRWLduHTIyMhAQENBm/yeffBITJkwwKnZ6ejoGDhwIrVaLGzdutHeqNsHBwQEODtI/JHTUuIzJEb99zWzW/PnzodVqkZOTY9G4Bw4cwNatW/HRRx+ZvG9ubi5CQ0Ph4uKCmJgYHDx4EEOGDBG9OtS9/X7+/HnRvoWFhVAoFKK3eA8ePIjf/e536Nq1K5RKJQIDA/H222/j3r17on1TUlLg7u6OqqoqjBo1Cu7u7vD19UV6ejq0Wi0A4Pz58/D19QUAZGdnC2/fL1q0CID+Z7spKSktvuWv2+fhw4fIzMxE//79oVar4ebmhsGDB2P//v1CHFPHBQCNRoMlS5YgNDQUSqUS3bp1w/z58/HgwQNRv27dumHEiBE4dOgQYmJi4OzsjJCQEPztb39re7EYkyF+espsVnBwMCZNmoR169Zh3rx5bb5abmxs1HvV6+rqCldXV+G2VqvFjBkzMGXKFERGRpo0n7y8PEydOhVxcXGYOXMmzp07h5deegne3t4IDAw0KZbOli1b0NDQgOnTp+OJJ55AcXExVq1ahcuXL2PLli2ivlqtFsOHD0dsbCxWrFiBffv24cMPP0RoaCimT58OX19ffPrpp5g+fTpGjx6NMWPGAACioqIMjj116lQkJCSI2vbs2YPPP/8cfn5+AIC6ujr89a9/xfjx45Gamor6+nrk5eVh+PDhKC4uRnR0tMnjAsCUKVOwceNGvPzyy5g9ezYOHz6MpUuX4vTp09i+fbuob3l5OV5++WVMnjwZycnJWL9+PVJSUtC/f3+Eh4ebdocz1tGIMRuTn59PAOiHH36giooKcnBwoLS0NGF7fHw8hYeHi/YJCgoiAHp/WVlZon5/+ctfSK1W0/Xr11uMZcjDhw/Jz8+PoqOj6cGDB0J7bm4uAaD4+Hi9+VdWVopi7N+/nwDQ/v37hbaGhga9sZYuXUoKhYIuXLggtCUnJxMAWrx4sahv3759qX///sLtn3/+2WDeRERZWVnU2kNCWVkZqdVqevbZZ0mj0RARkUajEeVLRHTr1i3q1KkTvf7662aNe+zYMQJAU6ZMEfVLT08nAPTf//5XaNOt64EDB4S269evk1KppNmzZ7eYC2NyxW9fM5sWEhKCiRMnIjc3F1evXm21b2xsLPbu3Sv6mzRpkrD95s2byMzMxMKFC4W3W4115MgRXL9+HdOmTROdOJaSkgK1Wm1aUs24uLgI/7579y5u3LiBuLg4EBFKSkr0+k+bNk10e/DgwTh37pzZ4zcfe/To0fDy8sLmzZthb28PALC3txfybWpqQk1NDTQaDQYMGIAff/zRrLF27doFAJg1a5aoXXeS3ldffSVq7927NwYPHizc9vX1RVhYmEXyZkxq/PY1s3kLFizAZ599hpycHHz88cct9vPx8dF7O/bRON7e3pgxY4bJc7hw4QIAoEePHqJ2R0dHhISEmBxP5+LFi8jMzMTOnTtx69Yt0bba2lrRbWdnZ70nE15eXnr7mSM1NRUVFRX47rvv8MQTT4i2bdy4ER9++CHOnDmDxsZGoT04ONissS5cuAA7Ozt0795d1O7v7w9PT0/hvtbp2rWrXgxL5c2Y1LgoM5sXEhKCCRMmIDc31+xLa8rKypCbm4uPPvoIV65cEdrv37+PxsZGnD9/HiqVCt7e3u2eb0tflKE7Iav57WeffRY1NTWYO3cuevbsCTc3N1RVVSElJQVNTU2i/rpXr5b28ccfY/Pmzdi0aROio6NF2zZt2oSUlBSMGjUKc+bMgZ+fH+zt7bF06VJUVFS0a1xjv1CkpbyJqF3jM9YRuCizx8KCBQuwadMmLFu2zKz9q6qq0NTUhLS0NKSlpeltDw4OxltvvdXiGdlBQUEAfinuQ4cOFdobGxtRWVmJPn36CG1eXl4AgNu3b4tiPPoK8MSJE/jf//6HjRs3it5m37t3r0m5NWfqN2cdPHgQ6enpmDlzJl577TW97Vu3bkVISAi2bdsmip2VlWX2uEFBQWhqakJZWRl69eoltFdXV+P27dvCfc3Y44g/U2aPhdDQUEyYMAFr167FtWvXTN4/IiIC27dv1/sLDw9H165dsX37dkyePLnF/QcMGABfX1+sWbMGDx8+FNo3bNigV3xDQ0MB/HLplY5Wq0Vubq6on+4VYPNXfETU6lv0bdGdaf7onAy5evUqXnnlFTz99NNYvny5wT6G5nj48GEUFRWZPe4LL7wAAHpPgFauXAkASEpKajMGY7aKXymzx8a7776Lzz77DGfPnjX5UhgfHx+MGjVKr11XGAxta87R0RHvvfcepk6diqFDh2Ls2LGorKxEfn6+3mfK4eHhGDhwIDIyMlBTUwNvb28UFBRAo9GI+vXs2ROhoaFIT09HVVUVVCoV/vnPf7brs1IXFxf07t0b//jHP/DUU0/B29sbERERBr9KNC0tDT///DPeeecdFBQUiLZFRUUhKioKI0aMwLZt2zB69GgkJSWhsrISa9asQe/evXHnzh2zxu3Tpw+Sk5ORm5uL27dvIz4+HsXFxdi4cSNGjRqF3/zmN2bnz5jsdei534yZofklUY/SXRpk6JKopKQkk8cy9pIonU8++YSCg4NJqVTSgAED6MCBAxQfHy+6JIqIqKKighISEkipVFKnTp1o/vz5tHfvXr1LokpLSykhIYHc3d3Jx8eHUlNT6fjx4wSA8vPzRXm7ubnpzcfQZU7fffcd9e/fn5ycnESXKT3aNz4+3uBlZM33aWpqog8++ICCgoJIqVRS37596d///jclJydTUFCQWeMSETU2NlJ2djYFBweTo6MjBQYGUkZGBt2/f1/Ur6V1NXSfM2YLFER8NgRj1qT7Ni/+MQbGWFv4M2XGGGNMJrgoM8YYYzLBRZkxxhiTCf5MmTHGGJMJfqXMGGOMyQQXZcYYY0wmjPrykKamJly5cgUeHh4mf00fY4wx9mtGRKivr0dAQADs7Fp/LWxUUb5y5YrZP9LOGGOMMeDSpUvo0qVLq32MKsoeHh5CQJVK1f6ZMcYYY78SdXV1CAwMFGppa4wqyrq3rFUqFRdlxhhjzAzGfPzLJ3oxxhhjMsFFmTHGGJMJLsqMMcaYTHBRZowxxmSCizJjjDEmE1yUGWOMMZngoswYY4zJBBdlxhhjTCa4KDPGGGMywUWZMcYYkwkuyowxxphMGPXd15ambSIUV9bgev19+Hk4IybYG/Z2v56fhJRj/lLOyZpjWSO2pWPKLZ6l5iO3OJaOJUVcqcewpXlIQQ65Sl6U95y8iux/leJq7X2hrbPaGVkv9kZiRGeppyM5OeYv5ZysOZY1Yls6ptziWWo+cotj6VhSxJV6DFuahxTkkquCiKitTnV1dVCr1aitrW3Xr0TtOXkV0zf9iEcH1D0P+XRCv8duoZuTY/5SzsmaY1kjtqVjyi2epeYjtziWjiVFXKnHsKV5SMHauZpSQyX7TFnbRMj+V6le0gCEtux/lULb1OZzBJskx/ylnJM1x7JGbEvHlFs8S81HbnEsHUuKuFKPYUvzkILccpWsKBdX1ojeFngUAbhaex/FlTVSTUlScsxfyjlZcyxrxLZ0TLnFs9R85BbH0rGkiCv1GLY0DynILVfJivL1+paTNqefrZFj/lLOyZpjWSO2pWPKrZ+lxpFbHEvHkiKu1GPY0jykILdcJSvKfh7OFu1na+SYv5RzsuZY1oht6Zhy62epceQWx9KxpIgr9Ri2NA8pyC1XyYpyTLA3Oqud0dLJ5Qr8cqZbTLC3VFOSlBzzl3JO1hzLGrEtHVNu8Sw1H7nFsXQsKeJKPYYtzUMKcstVsqJsb6dA1ou9AUAved3trBd7P7bXv8kxfynnZM2xrBHb0jHlFs9S85FbHEvHkiKu1GPY0jykILdcJf1Gr8SIzvh0Qj/4q8VvA/irnR+r0+tbIsf8pZyTNceyRmxLx5RbPEvNR25xLB1LirhSj2FL85CCnHKV9DplHTl8a0pHkmP+/I1e0sWUWzy5fRMXf6OXdGPY0jykYK1cTamhHVKUGWOMsV8LWX55CGOMMcZax0WZMcYYkwkuyowxxphMcFFmjDHGZIKLMmOMMSYTXJQZY4wxmeCizBhjjMkEF2XGGGNMJrgoM8YYYzLBRZkxxhiTCS7KjDHGmEw4GNNJ9/XYdXV1Vp0MY4wx9rjR1U4jfmrCuKJcX18PAAgMDGzHtBhjjLFfr/r6eqjV6lb7GPUrUU1NTbhy5Qo8PDygUFjmJ7vq6uoQGBiIS5cuPTa/PMU52QbOSf4et3wAzslWWCMnIkJ9fT0CAgJgZ9f6p8ZGvVK2s7NDly5dLDK5R6lUqsdmMXU4J9vAOcnf45YPwDnZCkvn1NYrZB0+0YsxxhiTCS7KjDHGmEx0WFFWKpXIysqCUqnsqClYHOdkGzgn+Xvc8gE4J1vR0TkZdaIXY4wxxqyP375mjDHGZIKLMmOMMSYTXJQZY4wxmeCizBhjjMkEF2XGGGNMJqxWlN9//33ExcXB1dUVnp6eRu1DRMjMzETnzp3h4uKChIQElJWVifrU1NTgtddeg0qlgqenJyZPnow7d+5YIQN9po59/vx5KBQKg39btmwR+hnaXlBQIEVKZt2fQ4YM0ZvvtGnTRH0uXryIpKQkuLq6ws/PD3PmzIFGo7FmKgJTc6qpqcGMGTMQFhYGFxcXdO3aFWlpaaitrRX1k3KdVq9ejW7dusHZ2RmxsbEoLi5utf+WLVvQs2dPODs7IzIyErt27RJtN+bYsjZTclq3bh0GDx4MLy8veHl5ISEhQa9/SkqK3nokJiZaOw0RU3LasGGD3nydnZ1FfWxtnQw9FigUCiQlJQl9OnKdDhw4gBdffBEBAQFQKBT48ssv29ynsLAQ/fr1g1KpRPfu3bFhwwa9PqYenyYhK8nMzKSVK1fSrFmzSK1WG7VPTk4OqdVq+vLLL+n48eP00ksvUXBwMN27d0/ok5iYSH369KHvv/+eDh48SN27d6fx48dbKQsxU8fWaDR09epV0V92dja5u7tTfX290A8A5efni/o1z9mazLk/4+PjKTU1VTTf2tpaYbtGo6GIiAhKSEigkpIS2rVrF/n4+FBGRoa10yEi03M6ceIEjRkzhnbu3Enl5eX0n//8h3r06EG//e1vRf2kWqeCggJycnKi9evX06lTpyg1NZU8PT2purraYP9vv/2W7O3t6U9/+hOVlpbSggULyNHRkU6cOCH0MebYsiZTc3r11Vdp9erVVFJSQqdPn6aUlBRSq9V0+fJloU9ycjIlJiaK1qOmpkaSfIhMzyk/P59UKpVovteuXRP1sbV1unnzpiifkydPkr29PeXn5wt9OnKddu3aRe+++y5t27aNAND27dtb7X/u3DlydXWlWbNmUWlpKa1atYrs7e1pz549Qh9T7yNTWa0o6+Tn5xtVlJuamsjf35+WL18utN2+fZuUSiVt3ryZiIhKS0sJAP3www9Cn927d5NCoaCqqiqLz705S40dHR1Nr7/+uqjNmP8s1mBuTvHx8fTWW2+1uH3Xrl1kZ2cnesD59NNPSaVS0YMHDywy95ZYap2++OILcnJyosbGRqFNqnWKiYmhN998U7it1WopICCAli5darD/K6+8QklJSaK22NhYmjp1KhEZd2xZm6k5PUqj0ZCHhwdt3LhRaEtOTqaRI0daeqpGMzWnth4LH4d1+vOf/0weHh50584doa2j10nHmOP3nXfeofDwcFHb2LFjafjw4cLt9t5HbZHNZ8qVlZW4du0aEhIShDa1Wo3Y2FgUFRUBAIqKiuDp6YkBAwYIfRISEmBnZ4fDhw9bdX6WGPvo0aM4duwYJk+erLftzTffhI+PD2JiYrB+/XqjfnezvdqT0+effw4fHx9EREQgIyMDDQ0NoriRkZHo1KmT0DZ8+HDU1dXh1KlTlk+kGUv9H6mtrYVKpYKDg/g3W6y9Tg8fPsTRo0dFx4GdnR0SEhKE4+BRRUVFov7AL/e3rr8xx5Y1mZPToxoaGtDY2Ahvb29Re2FhIfz8/BAWFobp06fj5s2bFp17S8zN6c6dOwgKCkJgYCBGjhwpOh4eh3XKy8vDuHHj4ObmJmrvqHUyVVvHkiXuo7YY9StRUrh27RoAiB7Idbd1265duwY/Pz/RdgcHB3h7ewt9rDm/9o6dl5eHXr16IS4uTtS+ePFiDB06FK6urvjmm2/whz/8AXfu3EFaWprF5m+IuTm9+uqrCAoKQkBAAH766SfMnTsXZ8+exbZt24S4htZRt82aLLFON27cwJIlS/DGG2+I2qVYpxs3bkCr1Rq8/86cOWNwn5bu7+bHja6tpT7WZE5Oj5o7dy4CAgJED4aJiYkYM2YMgoODUVFRgfnz5+P5559HUVER7O3tLZrDo8zJKSwsDOvXr0dUVBRqa2uxYsUKxMXF4dSpU+jSpYvNr1NxcTFOnjyJvLw8UXtHrpOpWjqW6urqcO/ePdy6davd/5fbYlJRnjdvHpYtW9Zqn9OnT6Nnz57tmpSUjM2pve7du4e///3vWLhwod625m19+/bF3bt3sXz5crMf7K2dU/NiFRkZic6dO2PYsGGoqKhAaGio2XFbI9U61dXVISkpCb1798aiRYtE2yy9Tsw4OTk5KCgoQGFhoejEqHHjxgn/joyMRFRUFEJDQ1FYWIhhw4Z1xFRbNWjQIAwaNEi4HRcXh169emHt2rVYsmRJB87MMvLy8hAZGYmYmBhRu62tU0czqSjPnj0bKSkprfYJCQkxayL+/v4AgOrqanTu3Flor66uRnR0tNDn+vXrov00Gg1qamqE/U1lbE7tHXvr1q1oaGjApEmT2uwbGxuLJUuW4MGDB2Z9KbpUOTWfLwCUl5cjNDQU/v7+emcjVldXA4Cs16m+vh6JiYnw8PDA9u3b4ejo2Gr/9q6TIT4+PrC3txfuL53q6uoW5+/v799qf2OOLWsyJyedFStWICcnB/v27UNUVFSrfUNCQuDj44Py8nKrP9i3JycdR0dH9O3bF+Xl5QBse53u3r2LgoICLF68uM1xpFwnU7V0LKlUKri4uMDe3r7d694mi3wy3QpTT/RasWKF0FZbW2vwRK8jR44Ifb7++mtJT/Qyd+z4+Hi9s3lb8t5775GXl5fZczWWpe7PQ4cOEQA6fvw4Ef3fiV7Nz0Zcu3YtqVQqun//vuUSMMDcnGpra2ngwIEUHx9Pd+/eNWosa61TTEwM/fGPfxRua7VaevLJJ1s90WvEiBGitkGDBumd6NXasWVtpuZERLRs2TJSqVRUVFRk1BiXLl0ihUJBO3bsaPd8jWFOTs1pNBoKCwujt99+m4hsd52IfnmcVyqVdOPGjTbHkHqddGDkiV4RERGitvHjx+ud6NWedW9znhaJYsCFCxeopKREuASopKSESkpKRJcChYWF0bZt24TbOTk55OnpSTt27KCffvqJRo4cafCSqL59+9Lhw4fp0KFD1KNHD0kviWpt7MuXL1NYWBgdPnxYtF9ZWRkpFAravXu3XsydO3fSunXr6MSJE1RWVkaffPIJubq6UmZmptXzITI9p/Lyclq8eDEdOXKEKisraceOHRQSEkLPPPOMsI/ukqjnnnuOjh07Rnv27CFfX19JL4kyJafa2lqKjY2lyMhIKi8vF126odFoiEjadSooKCClUkkbNmyg0tJSeuONN8jT01M4m33ixIk0b948of+3335LDg4OtGLFCjp9+jRlZWUZvCSqrWPLmkzNKScnh5ycnGjr1q2i9dA9ftTX11N6ejoVFRVRZWUl7du3j/r160c9evSw+hM/c3PKzs6mr7/+mioqKujo0aM0btw4cnZ2plOnTonytqV10nn66adp7Nixeu0dvU719fVC7QFAK1eupJKSErpw4QIREc2bN48mTpwo9NddEjVnzhw6ffo0rV692uAlUa3dR+1ltaKcnJxMAPT+9u/f/3+D///rPnWamppo4cKF1KlTJ1IqlTRs2DA6e/asKO7Nmzdp/Pjx5O7uTiqVin7/+9+LCr01tTV2ZWWlXo5ERBkZGRQYGEharVYv5u7duyk6Oprc3d3Jzc2N+vTpQ2vWrDHY1xpMzenixYv0zDPPkLe3NymVSurevTvNmTNHdJ0yEdH58+fp+eefJxcXF/Lx8aHZs2eLLi+SU0779+83+H8VAFVWVhKR9Ou0atUq6tq1Kzk5OVFMTAx9//33wrb4+HhKTk4W9f/iiy/oqaeeIicnJwoPD6evvvpKtN2YY8vaTMkpKCjI4HpkZWUREVFDQwM999xz5OvrS46OjhQUFESpqakWe2C0Rk4zZ84U+nbq1IleeOEF+vHHH0XxbG2diIjOnDlDAOibb77Ri9XR69TSsa3LITk5meLj4/X2iY6OJicnJwoJCRHVKJ3W7qP24t9TZowxxmRCNtcpM8YYY792XJQZY4wxmeCizBhjjMkEF2XGGGNMJrgoM8YYYzLBRZkxxhiTCS7KjDHGmExwUWaMMcZkgosyY4wxJhNclBljjDGZ4KLMGGOMycT/A6yb4GGS+06rAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 600x50 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(6, .5))\n",
        "ax.scatter(x=sorted(nf4_state['weight.quant_map'].tolist()), y=[0]*16)\n",
        "ax.set_yticks([])\n",
        "ax.set_title('NF4 quantization')"
      ],
      "id": "gimZ4RTia5lT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEQxunHda5lT"
      },
      "source": [
        "### Coming Up in \"Fine-Tuning LLMs\"\n",
        "\n",
        "As huge linear layers are being replaced by their quantized versions to reduce the model’s memory footprint, a\n",
        "new issue arises. These quantized layers cannot be easily updated, thus rendering fine-tuning next to\n",
        "impossible. Could a new kind of layer be the solution to this conundrum? Find out in the next thrilling chapter\n",
        "of \"Fine-Tuning LLMs.\""
      ],
      "id": "tEQxunHda5lT"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}